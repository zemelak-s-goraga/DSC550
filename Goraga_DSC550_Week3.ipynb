{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining (DSC550-T301_2245_1)\n",
    "\n",
    "Assignement Week 3;\n",
    "\n",
    "Author: Zemelak Goraga;\n",
    "\n",
    "Date: 03/30/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EbErn_eRis5"
   },
   "outputs": [],
   "source": [
    "pip install pandas textblob nltk scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nRYmEtvjRu6k"
   },
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from textblob import TextBlob\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  sentiment                                             review\n",
      "0  5814_8          1  With all this stuff going down at the moment w...\n",
      "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
      "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
      "3  3630_4          0  It must be assumed that those who praised this...\n",
      "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a DataFrame, skipping lines with errors\n",
    "train_data = pd.read_csv('labeledTrainData.tsv', error_bad_lines=False, sep='\\t')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnoZgfHdZUZt",
    "outputId": "374c23b9-75e9-4e31-c8dc-a67bea51ab2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews: 12500\n",
      "Number of negative reviews: 12500\n"
     ]
    }
   ],
   "source": [
    "# 2. Counting positive and negative reviews\n",
    "positive_reviews = train_data[train_data['sentiment'] == 1]\n",
    "negative_reviews = train_data[train_data['sentiment'] == 0]\n",
    "print(\"Number of positive reviews:\", len(positive_reviews))\n",
    "print(\"Number of negative reviews:\", len(negative_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TTTkdGblZUgs"
   },
   "outputs": [],
   "source": [
    "# 3. Using TextBlob to classify each movie review\n",
    "def classify_sentiment_textblob(review):\n",
    "    analysis = TextBlob(review)\n",
    "    if analysis.sentiment.polarity >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "train_data['predicted_sentiment_textblob'] = train_data['review'].apply(classify_sentiment_textblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nKuaZwv7ZUn8",
    "outputId": "9a2555e1-ae32-41b8-e584-0b58cc936088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of TextBlob model: 0.68524\n"
     ]
    }
   ],
   "source": [
    "# 4. Checking accuracy of the TextBlob model\n",
    "textblob_accuracy = accuracy_score(train_data['sentiment'], train_data['predicted_sentiment_textblob'])\n",
    "print(\"Accuracy of TextBlob model:\", textblob_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FdiWmlYRZUwL",
    "outputId": "5420b81c-8827-40d9-88b9-d6b505c15d4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\MariaStella\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of VADER model: 0.69356\n"
     ]
    }
   ],
   "source": [
    "# 5. Using VADER sentiment analyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "def classify_sentiment_vader(review):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    compound_score = analyzer.polarity_scores(review)['compound']\n",
    "    if compound_score >= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "train_data['predicted_sentiment_vader'] = train_data['review'].apply(classify_sentiment_vader)\n",
    "\n",
    "vader_accuracy = accuracy_score(train_data['sentiment'], train_data['predicted_sentiment_vader'])\n",
    "print(\"Accuracy of VADER model:\", vader_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pyvsnUh9ZU3P"
   },
   "outputs": [],
   "source": [
    "# Part 2\n",
    "# Prepping Text for a Custom Model\n",
    "# 2.1 Convert all text to lowercase letters\n",
    "train_data['review'] = train_data['review'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0eTJZ9Wzc9wJ"
   },
   "outputs": [],
   "source": [
    "# 2.2 Remove punctuation and special characters from the text\n",
    "train_data['review'] = train_data['review'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ld5h9OHReIop",
    "outputId": "ec4afa46-b41e-49b0-c92b-adb38b65a13a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MariaStella\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJZhPUzqeI3e",
    "outputId": "50555ac7-afa8-473e-81a8-8d318e26687d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MariaStella\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "b9ac5wwddG9-"
   },
   "outputs": [],
   "source": [
    "# 2.3 Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "train_data['review'] = train_data['review'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "QpN1zlrzdHJ0"
   },
   "outputs": [],
   "source": [
    "# 2.4 Apply NLTKâ€™s PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "train_data['review'] = train_data['review'].apply(lambda x: ' '.join([stemmer.stem(word) for word in word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wjnNai0IdHUk"
   },
   "outputs": [],
   "source": [
    "# 2.4.1 Create a bag-of-words matrix\n",
    "count_vectorizer = CountVectorizer()\n",
    "bag_of_words_matrix = count_vectorizer.fit_transform(train_data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2bLuvoldQ_c",
    "outputId": "a389cf88-b37a-45aa-e238-360f7ba098d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of bag-of-words matrix: (25000, 92345)\n"
     ]
    }
   ],
   "source": [
    "# 2.4.2 Display dimensions of bag-of-words matrix\n",
    "print(\"Dimensions of bag-of-words matrix:\", bag_of_words_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4fh9qWh4dRM6"
   },
   "outputs": [],
   "source": [
    "# 2.4.3 Create a term frequency-inverse document frequency (tf-idf) matrix\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_matrix = tfidf_transformer.fit_transform(bag_of_words_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fy2Cj95RdRcq",
    "outputId": "ed545fd4-5636-47b8-fb04-d2b0219cc1e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of tf-idf matrix: (25000, 92345)\n"
     ]
    }
   ],
   "source": [
    "# 2.4.4 Display dimensions of tf-idf matrix\n",
    "print(\"Dimensions of tf-idf matrix:\", tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short Report:\n",
    "\n",
    "Topic: Sentiment Analysis of Movie Reviews\n",
    "\n",
    "Summary:\n",
    "This report presents the results of a sentiment analysis conducted on a dataset of movie reviews obtained from Kaggle. The analysis aimed to classify the sentiment of the reviews as either positive or negative using two different prebuilt sentiment analysis tools, namely TextBlob and VADER. Additionally, the text data was preprocessed to prepare it for custom model building, including steps such as lowercase conversion, punctuation removal, stop word removal, and stemming. The report concludes with a discussion on the results, implications, and potential future directions.\n",
    "\n",
    "Introduction:\n",
    "In today's digital age, online reviews play a crucial role in shaping consumer perceptions and decision-making processes. Sentiment analysis, a subfield of natural language processing (NLP), offers a systematic approach to extract and quantify sentiments expressed in textual data. Understanding the sentiment of movie reviews can provide valuable insights into audience reactions, critical acclaim, and commercial success.\n",
    "\n",
    "Statement of the Problem:\n",
    "The objective of this study is to perform sentiment analysis on a dataset of movie reviews and evaluate the effectiveness of two prebuilt sentiment analysis tools, TextBlob and VADER. Additionally, the text data will be preprocessed to prepare it for custom model building, enabling further analysis and exploration.\n",
    "\n",
    "Methodology:\n",
    "Data Collection: The movie review dataset was obtained from Kaggle's \"Bag of Words Meets Bags of Popcorn\" competition using the Kaggle API.\n",
    "Data Preprocessing:\n",
    "Conversion of text to lowercase.\n",
    "Removal of punctuation and special characters.\n",
    "Elimination of stop words.\n",
    "Application of NLTK's PorterStemmer for word stemming.\n",
    "Sentiment Analysis:\n",
    "Utilization of TextBlob and VADER for sentiment classification.\n",
    "TextBlob classified reviews with polarity scores >= 0 as positive and < 0 as negative.\n",
    "VADER assigned positive sentiment to reviews with compound scores >= 0 and negative sentiment otherwise.\n",
    "Model Evaluation:\n",
    "Calculation of accuracy scores for TextBlob and VADER models.\n",
    "Custom Model Preprocessing:\n",
    "Creation of bag-of-words and tf-idf matrices from preprocessed text data.\n",
    "\n",
    "\n",
    "Results:\n",
    "Data Overview:\n",
    "The dataset consists of movie reviews with 12,500 positive and 12,500 negative reviews.\n",
    "There are a total of 25,000 reviews in the dataset, evenly split between positive and negative sentiments (12,500 each).\n",
    "\n",
    "Sentiment Analysis Results:\n",
    "TextBlob Model Accuracy: 68.524%\n",
    "VADER Model Accuracy: 69.356%\n",
    "Custom Model Preprocessing:\n",
    "\n",
    "The preprocessing steps included converting text to lowercase, removing punctuation and special characters, eliminating stop words, and applying stemming using NLTK's PorterStemmer.\n",
    "\n",
    "The dimensions of the bag-of-words matrix and the tf-idf matrix are both (25,000, 92,345), indicating 25,000 documents (reviews) and 92,345 unique words in the vocabulary.\n",
    "These results provide insights into the performance of sentiment analysis models and the preprocessing steps necessary for text data preparation. Further analysis and model refinement can be conducted based on these findings to improve sentiment classification accuracy and explore additional features for enhancing model performance.\n",
    "\n",
    "\n",
    "\n",
    "Discussion and conclusions:\n",
    "\n",
    "Model Performance:\n",
    "\n",
    "Both TextBlob and VADER sentiment analysis models demonstrated reasonable accuracy in classifying movie review sentiments, with TextBlob achieving an accuracy of 68.524% and VADER achieving 69.356%.\n",
    "\n",
    "While VADER marginally outperformed TextBlob in this dataset, both models showed effectiveness in sentiment classification, indicating their utility in analyzing movie reviews.\n",
    "Data Distribution:\n",
    "\n",
    "The dataset comprises 25,000 movie reviews, evenly split between positive and negative sentiments, with 12,500 reviews in each category. This balanced distribution ensures that the dataset is representative and can provide reliable insights into sentiment patterns.\n",
    "Preprocessing Importance:\n",
    "\n",
    "Preprocessing steps such as converting text to lowercase, removing punctuation, eliminating stop words, and applying stemming were crucial in preparing the text data for sentiment analysis. These steps helped in standardizing the input data and reducing noise, thereby improving the performance of sentiment analysis models.\n",
    "Feature Representation:\n",
    "\n",
    "The bag-of-words and tf-idf matrices, with dimensions (25,000, 92,345), represented the preprocessed text data and provided a rich feature space for modeling. These matrices captured the frequency and importance of words in each document, enabling effective sentiment analysis.\n",
    "Future Directions:\n",
    "\n",
    "Further exploration could involve refining sentiment analysis models to improve accuracy and account for nuanced expressions in movie reviews.\n",
    "\n",
    "Additionally, incorporating additional features such as review length, word frequency, or genre-specific analysis could enhance sentiment classification accuracy and provide deeper insights into audience reactions.\n",
    "Deployment of sentiment analysis models in real-world applications, such as recommendation systems or market research, could offer valuable insights for stakeholders in the movie industry.\n",
    "\n",
    "In conclusion, the sentiment analysis of movie reviews using TextBlob, VADER, and custom preprocessing techniques proved effective in classifying sentiments and extracting meaningful insights. These findings lay the groundwork for further research and application of sentiment analysis techniques in understanding audience reactions and enhancing decision-making processes in the movie industry.\n",
    "\n",
    "\n",
    "Way Forward:\n",
    "\n",
    "Moving forward, it is imperative to focus on refining sentiment analysis models like TextBlob and VADER to enhance accuracy and robustness, while also exploring additional features such as review length and sentiment intensity to enrich the analysis process. Custom model development using machine learning algorithms and deployment in real-world applications like recommendation systems and market research can provide valuable insights for stakeholders in the movie industry. Continuous learning, adaptation, and collaboration with domain experts will be key in driving iterative improvements and staying abreast of advancements in natural language processing and sentiment analysis techniques, ultimately empowering stakeholders to make informed decisions and better understand audience sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
